{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This memory describes the steps followed in the preparation of the Kschool 15th Edition Data Science Master TFM: 'Test your business viability' as well as the main results\n",
    "\n",
    "Some **background**   \n",
    "When I started to look for an idea for the project, I came into a open dataset of Madrid city council that contains information about the different retail stores and activities licensed in Madrid since 2014. See references in: https://datos.madrid.es/sites/v/index.jsp?vgnextoid=66665cde99be2410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD   \n",
    "This data reminded me about the feeling that I had that some people open their business without a detailed business case and many of them close in a short period of time. So I decided to analyse the the commercial premises census evolution and look for some pattern.\n",
    "\n",
    "So, coming to the **TFM objective**, the main goal of this TFM is to use previous information as a base for an advanced analytics model that predicts the probability that a commercial premises will be closed in a time.   \n",
    "This is a supervised classification problem and has allowed me to deep dive in the use of Pandas and in this kind of algorithms. \n",
    "\n",
    "Some **important decisions:**   \n",
    "During the project preparation and after some time working with the information, the quality of the data was not good enough. I had to take some decissions:\n",
    "- **About Data sources**: 2014 files were in a different format and with different identifiers and tags so I had to base my study in the information available since 2015 till september 2019.  \n",
    "\n",
    "\n",
    "- **About Target variable**: I wanted to analyze the probability of a business to open and close in a 2 years timeframe but I had not enough samples (less than 1% over the total population). Finally, I defined my target variable as the commercial premises that closed between 2017 till the date (3 years timeframe).\n",
    "\n",
    "\n",
    "- **Variables**: I have not found good predictive variables. I started with the commercial stores files with no results so I generated additional features trying to get some results.  \n",
    "I use adittional information about Madrid population census also available in Madrid Opendata Portal and some information about the floating population in the different districts of Madrid during an April's week of 2018, kindly provided by Kinneo\n",
    "\n",
    "\n",
    "- **About the Models**: I have used Logistic Regression as a baseline. \n",
    "I started testing KNN, Decission Tree, Random Forest and XGboost. The results were quite similar and very bad (aroung 60% AUC) so I focused on improving Random Forest and XGboost.  \n",
    "For the sake of simplicity, I will only show the analysis performed with Logistic Regression, Random Forest and XGboost.  \n",
    "Due to the low predictibility obtained with the models in the end, the deliverable to the end user will be a Tableau dashboard with a descriptive analysis of the commercial premises in Madrid  \n",
    "\n",
    "\n",
    "- **Metrics**: the main metrics are Recall, AUC and since it is an umbalanced dataset, I have also focused on Precision and Recall curve and f1_score \n",
    "\n",
    "The results of the project are presented in:\n",
    "- Jupyter notebooks: data preparation and models results\n",
    "- Nbviewer (html) (to ilustrate some steps of the process whose execution takes a lot of time (i.e: XGboost tuning)\n",
    "- Tableau: maps of Madrid with a descriptive analysis of the different types of commercial premises and status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [Data Cleaning Notebook](./TBV1_data_cleaning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [Data Cleaning Notebook](./TBV1_data_cleaning.ipynb)\n",
    "\n",
    "(http://localhost:8888/notebooks/Python_notebooks/TFM/TBV/TBV_v1/TBVv1_data_cleaningv2.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [Classification Modeling Notebook](http://localhost:8888/notebooks/Python_notebooks/TFM/TBV/TBV_v1/TBV1_classification_model.ipynb#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "./TBV1_data_cleaning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
